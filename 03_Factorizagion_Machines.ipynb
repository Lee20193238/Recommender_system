{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### FM(Factorizagion Machines)"
      ],
      "metadata": {
        "id": "NK99pkx3Zakd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFHuMF9Uw0LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8761f56d-f1bd-4e6c-b78e-c88901de3d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding  0  cases...\n",
            "Encoding  10000  cases...\n",
            "Encoding  20000  cases...\n",
            "Encoding  30000  cases...\n",
            "Encoding  40000  cases...\n",
            "Encoding  50000  cases...\n",
            "Encoding  60000  cases...\n",
            "Encoding  70000  cases...\n",
            "Encoding  80000  cases...\n",
            "Encoding  90000  cases...\n",
            "Iteration: 10 ; Train RMSE = 1.077285 ; Test RMSE = 1.080299\n",
            "Iteration: 20 ; Train RMSE = 1.052217 ; Test RMSE = 1.056971\n",
            "Iteration: 30 ; Train RMSE = 1.024868 ; Test RMSE = 1.032277\n",
            "Iteration: 40 ; Train RMSE = 0.997012 ; Test RMSE = 1.008370\n",
            "Iteration: 50 ; Train RMSE = 0.972730 ; Test RMSE = 0.988633\n",
            "Iteration: 60 ; Train RMSE = 0.954244 ; Test RMSE = 0.974478\n",
            "Iteration: 70 ; Train RMSE = 0.940765 ; Test RMSE = 0.964771\n",
            "Iteration: 80 ; Train RMSE = 0.930714 ; Test RMSE = 0.958019\n",
            "Iteration: 90 ; Train RMSE = 0.922982 ; Test RMSE = 0.953242\n",
            "Iteration: 100 ; Train RMSE = 0.916866 ; Test RMSE = 0.949812\n",
            "Iteration: 110 ; Train RMSE = 0.911894 ; Test RMSE = 0.947306\n",
            "Iteration: 120 ; Train RMSE = 0.907737 ; Test RMSE = 0.945429\n",
            "Iteration: 130 ; Train RMSE = 0.904162 ; Test RMSE = 0.943984\n",
            "Iteration: 140 ; Train RMSE = 0.901004 ; Test RMSE = 0.942836\n",
            "Iteration: 150 ; Train RMSE = 0.898149 ; Test RMSE = 0.941899\n",
            "Iteration: 160 ; Train RMSE = 0.895515 ; Test RMSE = 0.941114\n",
            "Iteration: 170 ; Train RMSE = 0.893045 ; Test RMSE = 0.940444\n",
            "Iteration: 180 ; Train RMSE = 0.890699 ; Test RMSE = 0.939863\n",
            "Iteration: 190 ; Train RMSE = 0.888453 ; Test RMSE = 0.939355\n",
            "Iteration: 200 ; Train RMSE = 0.886288 ; Test RMSE = 0.938912\n",
            "Iteration: 210 ; Train RMSE = 0.884194 ; Test RMSE = 0.938526\n",
            "Iteration: 220 ; Train RMSE = 0.882165 ; Test RMSE = 0.938195\n",
            "Iteration: 230 ; Train RMSE = 0.880196 ; Test RMSE = 0.937915\n",
            "Iteration: 240 ; Train RMSE = 0.878285 ; Test RMSE = 0.937685\n",
            "Iteration: 250 ; Train RMSE = 0.876430 ; Test RMSE = 0.937504\n",
            "Iteration: 260 ; Train RMSE = 0.874631 ; Test RMSE = 0.937367\n",
            "Iteration: 270 ; Train RMSE = 0.872885 ; Test RMSE = 0.937274\n",
            "Iteration: 280 ; Train RMSE = 0.871190 ; Test RMSE = 0.937221\n",
            "Iteration: 290 ; Train RMSE = 0.869545 ; Test RMSE = 0.937204\n",
            "Iteration: 300 ; Train RMSE = 0.867946 ; Test RMSE = 0.937221\n",
            "Iteration: 310 ; Train RMSE = 0.866392 ; Test RMSE = 0.937268\n",
            "289 0.9372040272221506\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('/content/drive/MyDrive/movielens/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
        "\n",
        "i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL',\n",
        "          'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy',\n",
        "          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
        "          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "movies = pd.read_csv('/content/drive/MyDrive/movielens/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
        "\n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/movielens/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
        "\n",
        "# User encoding\n",
        "user_dict = {}\n",
        "for i in set(users['user_id']):\n",
        "    user_dict[i] = len(user_dict)\n",
        "n_user = len(user_dict)\n",
        "\n",
        "# Item encoding\n",
        "item_dict = {}\n",
        "start_point = n_user\n",
        "for i in set(movies['movie_id']):\n",
        "    item_dict[i] = start_point + len(item_dict)\n",
        "n_item = len(item_dict)\n",
        "start_point += n_item\n",
        "\n",
        "# Occupation encoding\n",
        "occ_dict = {}\n",
        "for i in set(users['occupation']):\n",
        "    occ_dict[i] = start_point + len(occ_dict)\n",
        "n_occ = len(occ_dict)\n",
        "start_point += n_occ\n",
        "\n",
        "# Gender encoding\n",
        "gender_dict = {}\n",
        "for i in set(users['sex']):\n",
        "    gender_dict[i] = start_point + len(gender_dict)\n",
        "n_gender = len(gender_dict)\n",
        "start_point += n_gender\n",
        "\n",
        "# Genre encoding\n",
        "genre_dict = {}\n",
        "genre = ['unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy',\n",
        "          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
        "          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "for i in genre:\n",
        "    genre_dict[i] = start_point + len(genre_dict)\n",
        "n_genre = len(genre_dict)\n",
        "start_point += n_genre\n",
        "age_index = start_point\n",
        "start_point += 1\n",
        "num_x = start_point\n",
        "\n",
        "\n",
        "movies = movies.drop(['title', 'release date', 'video release date', 'IMDB URL'], axis=1)\n",
        "users = users.drop(['zip_code'], axis=1)\n",
        "ratings = ratings.drop(['timestamp'], axis=1)\n",
        "x = pd.merge(ratings, movies, how='outer', on='movie_id')\n",
        "x = pd.merge(x, users, how='outer', on='user_id')\n",
        "x = shuffle(x, random_state=1)\n",
        "\n",
        "# Generate X data\n",
        "data = []\n",
        "y = []\n",
        "age_mean = np.mean(x['age'])\n",
        "age_std = np.std(x['age'])\n",
        "w0 = np.mean(x['rating'])\n",
        "for i in range(len(x)):\n",
        "    case = x.iloc[i]\n",
        "    x_index = []\n",
        "    x_value = []\n",
        "    x_index.append(user_dict[case['user_id']])     # User id encoding\n",
        "    x_value.append(1)\n",
        "    x_index.append(item_dict[case['movie_id']])    # Movie id encoding\n",
        "    x_value.append(1)\n",
        "    x_index.append(occ_dict[case['occupation']])   # Occupation id encoding\n",
        "    x_value.append(1)\n",
        "    x_index.append(gender_dict[case['sex']])       # Gender id encoding\n",
        "    x_value.append(1)\n",
        "    for j in genre:\n",
        "        if case[j] == 1:               # 해당 장르가 1\n",
        "            x_index.append(genre_dict[j])\n",
        "            x_value.append(1)\n",
        "    x_index.append(age_index)\n",
        "    x_value.append((case['age'] - age_mean) / age_std)\n",
        "    data.append([x_index, x_value])\n",
        "    y.append(case['rating'] - w0)\n",
        "    if (i % 10000) == 0:\n",
        "        print('Encoding ', i, ' cases...')\n",
        "\n",
        "def RMSE(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
        "\n",
        "class FM():\n",
        "    def __init__(self, N, K, data, y, alpha, beta, train_ratio=0.75, iterations=100, tolerance=0.005, l2_reg=True, verbose=True):\n",
        "        self.K = K # Number of latent factors\n",
        "        self.N = N # Number of x (variables)\n",
        "        self.n_cases = len(data) # N of observations\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.iterations = iterations\n",
        "        self.l2_reg = l2_reg\n",
        "        self.tolerance = tolerance\n",
        "        self.verbose = verbose\n",
        "        # w 초기화\n",
        "        self.w = np.random.normal(scale=1./self.N, size=(self.N))\n",
        "        # v 초기화\n",
        "        self.v = np.random.normal(scale=1./self.K, size=(self.N, self.K))\n",
        "        # Train/Test 분리\n",
        "        cutoff = int(train_ratio * len(data))\n",
        "        self.train_x = data[:cutoff]\n",
        "        self.test_x = data[cutoff:]\n",
        "        self.train_y = y[:cutoff]\n",
        "        self.test_y = y[cutoff:]\n",
        "\n",
        "    def test(self): # Training 하면서 RMSE 계산\n",
        "        # SGD를 iterations 숫자만큼 수행\n",
        "        best_RMSE = 10000\n",
        "        best_iteration = 0\n",
        "        training_process = []\n",
        "        for i in range(self.iterations):\n",
        "            rmse1 = self.sgd(self.train_x, self.train_y) # SGD & Train RMSE 계산\n",
        "            rmse2 = self.test_rmse(self.test_x, self.test_y) # Test RMSE 계산\n",
        "            training_process.append((i, rmse1, rmse2))\n",
        "            if self.verbose:\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(\"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\" % (i+1, rmse1, rmse2))\n",
        "            if best_RMSE > rmse2: # New best record\n",
        "                best_RMSE = rmse2\n",
        "                best_iteration = i\n",
        "            elif (rmse2 - best_RMSE) > self.tolerance: # RMSE is increasing over tolerance\n",
        "                break\n",
        "        print(best_iteration, best_RMSE)\n",
        "        return training_process\n",
        "\n",
        "    # w, v 업데이트를 위한 SGD\n",
        "    def sgd(self, x_data, y_data):\n",
        "        y_pred = []\n",
        "        for data, y in zip(x_data, y_data):\n",
        "            x_idx = data[0]\n",
        "            x_0 = np.array(data[1]) # xi axis=0 [1, 2, 3]\n",
        "            x_1 = x_0.reshape(-1, 1) # xi axis=1 [[1], [2], [3]]\n",
        "\n",
        "            # biases\n",
        "            bias_score = np.sum(self.w[x_idx] * x_0)\n",
        "\n",
        "            # score 계산\n",
        "            vx = self.v[x_idx] * (x_1)          # v matrix * x\n",
        "            sum_vx = np.sum(vx, axis=0)         # sigma(vx)\n",
        "            sum_vx_2 = np.sum(vx * vx, axis=0)  # ( v matrix * x )의 제곱\n",
        "            latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
        "\n",
        "            # 예측값 계산\n",
        "            y_hat = bias_score + latent_score\n",
        "            y_pred.append(y_hat)\n",
        "            error = y - y_hat\n",
        "            # w, v 업데이트\n",
        "            if self.l2_reg: # regularization 있는 경우\n",
        "                self.w[x_idx] += error * self.alpha * (x_0 - self.beta * self.w[x_idx])\n",
        "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1) - self.beta * self.v[x_idx])\n",
        "            else: # regularization이 없는 경우\n",
        "                self.w[x_idx] += error * self.alpha * x_0\n",
        "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1))\n",
        "        return RMSE(y_data, y_pred)\n",
        "\n",
        "    def test_rmse(self, x_data, y_data):\n",
        "        y_pred = []\n",
        "        for data , y in zip(x_data, y_data):\n",
        "            y_hat = self.predict(data[0], data[1])\n",
        "            y_pred.append(y_hat)\n",
        "        return RMSE(y_data, y_pred)\n",
        "\n",
        "    def predict(self, idx, x):\n",
        "        x_0 = np.array(x)\n",
        "        x_1 = x_0.reshape(-1, 1)\n",
        "\n",
        "        # biases\n",
        "        bias_score = np.sum(self.w[idx] * x_0)\n",
        "\n",
        "        # score 계산\n",
        "        vx = self.v[idx] * (x_1)\n",
        "        sum_vx = np.sum(vx, axis=0)\n",
        "        sum_vx_2 = np.sum(vx * vx, axis=0)\n",
        "        latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
        "\n",
        "        # 예측값 계산\n",
        "        y_hat = bias_score + latent_score\n",
        "        return y_hat\n",
        "\n",
        "K = 200\n",
        "fm1 = FM(num_x, K, data, y, alpha=0.00005, beta=0.002, train_ratio=0.75, iterations=900, tolerance=0.0001, l2_reg=True, verbose=True)\n",
        "result = fm1.test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "boDSX3hjwl4P",
        "outputId": "8905f12e-6647-43d3-e581-d498f6714c33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding  0  cases...\n",
            "Encoding  10000  cases...\n",
            "Encoding  20000  cases...\n",
            "Encoding  30000  cases...\n",
            "Encoding  40000  cases...\n",
            "Encoding  50000  cases...\n",
            "Encoding  60000  cases...\n",
            "Encoding  70000  cases...\n",
            "Encoding  80000  cases...\n",
            "Encoding  90000  cases...\n",
            "Iteration: 10 ; Train RMSE = 0.955978 ; Test RMSE = 0.972694\n",
            "Iteration: 20 ; Train RMSE = 0.934230 ; Test RMSE = 0.957413\n",
            "Iteration: 30 ; Train RMSE = 0.925388 ; Test RMSE = 0.951440\n",
            "Iteration: 40 ; Train RMSE = 0.920597 ; Test RMSE = 0.948416\n",
            "Iteration: 50 ; Train RMSE = 0.917481 ; Test RMSE = 0.946666\n",
            "Iteration: 60 ; Train RMSE = 0.914961 ; Test RMSE = 0.945486\n",
            "Iteration: 70 ; Train RMSE = 0.912200 ; Test RMSE = 0.944432\n",
            "Iteration: 80 ; Train RMSE = 0.908096 ; Test RMSE = 0.943015\n",
            "Iteration: 90 ; Train RMSE = 0.900925 ; Test RMSE = 0.940520\n",
            "Iteration: 100 ; Train RMSE = 0.888761 ; Test RMSE = 0.936268\n",
            "Iteration: 110 ; Train RMSE = 0.871240 ; Test RMSE = 0.930623\n",
            "Iteration: 120 ; Train RMSE = 0.849547 ; Test RMSE = 0.924955\n",
            "Iteration: 130 ; Train RMSE = 0.823884 ; Test RMSE = 0.919996\n",
            "Iteration: 140 ; Train RMSE = 0.793535 ; Test RMSE = 0.915938\n",
            "Iteration: 150 ; Train RMSE = 0.758270 ; Test RMSE = 0.913087\n",
            "Iteration: 160 ; Train RMSE = 0.718876 ; Test RMSE = 0.911751\n",
            "Iteration: 170 ; Train RMSE = 0.676760 ; Test RMSE = 0.912023\n",
            "162 0.9116662596644332\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# data 불러오기\n",
        "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/movielens/u.data', sep='\\t', names=r_cols, encoding='latin-1')\n",
        "\n",
        "# User encoding\n",
        "user_dict = {}\n",
        "for i in set(ratings['user_id']):\n",
        "    user_dict[i] = len(user_dict)\n",
        "n_user = len(user_dict)\n",
        "# Item encoding\n",
        "item_dict = {}\n",
        "start_point = n_user\n",
        "for i in set(ratings['movie_id']):\n",
        "    item_dict[i] = start_point + len(item_dict)\n",
        "n_item = len(item_dict)\n",
        "start_point += n_item\n",
        "num_x = start_point # Total number of x\n",
        "ratings = shuffle(ratings, random_state=1)\n",
        "\n",
        "# Generate X data\n",
        "data = []\n",
        "y = []\n",
        "w0 = np.mean(ratings['rating'])\n",
        "for i in range(len(ratings)):\n",
        "    case = ratings.iloc[i]\n",
        "    x_index = []\n",
        "    x_value = []\n",
        "    x_index.append(user_dict[case['user_id']]) # User id encoding\n",
        "    x_value.append(1)\n",
        "    x_index.append(item_dict[case['movie_id']]) # Movie id encoding\n",
        "    x_value.append(1)\n",
        "    data.append([x_index, x_value])\n",
        "    y.append(case['rating'] - w0)\n",
        "    if (i % 10000) == 0:\n",
        "        print('Encoding ', i, ' cases...')\n",
        "\n",
        "def RMSE(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))\n",
        "\n",
        "class FM():\n",
        "    def __init__(self, N, K, data, y, alpha, beta, train_ratio=0.75, iterations=100, tolerance=0.005, l2_reg=True, verbose=True):\n",
        "        self.K = K # Number of latent factors\n",
        "        self.N = N # Number of x (variables)\n",
        "        self.n_cases = len(data) # N of observations\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.iterations = iterations\n",
        "        self.l2_reg = l2_reg\n",
        "        self.tolerance = tolerance\n",
        "        self.verbose = verbose\n",
        "        # w 초기화\n",
        "        self.w = np.random.normal(scale=1./self.N, size=(self.N))\n",
        "        # v 초기화\n",
        "        self.v = np.random.normal(scale=1./self.K, size=(self.N, self.K))\n",
        "        # Train/Test 분리\n",
        "        cutoff = int(train_ratio * len(data))\n",
        "        self.train_x = data[:cutoff]\n",
        "        self.test_x = data[cutoff:]\n",
        "        self.train_y = y[:cutoff]\n",
        "        self.test_y = y[cutoff:]\n",
        "\n",
        "    def test(self): # Training 하면서 RMSE 계산\n",
        "        # SGD를 iterations 숫자만큼 수행\n",
        "        best_RMSE = 10000\n",
        "        best_iteration = 0\n",
        "        training_process = []\n",
        "        for i in range(self.iterations):\n",
        "            rmse1 = self.sgd(self.train_x, self.train_y) # SGD & Train RMSE 계산\n",
        "            rmse2 = self.test_rmse(self.test_x, self.test_y) # Test RMSE 계산\n",
        "            training_process.append((i, rmse1, rmse2))\n",
        "            if self.verbose:\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(\"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\" % (i+1, rmse1, rmse2))\n",
        "            if best_RMSE > rmse2: # New best record\n",
        "                best_RMSE = rmse2\n",
        "                best_iteration = i\n",
        "            elif (rmse2 - best_RMSE) > self.tolerance: # RMSE is increasing over tolerance\n",
        "                break\n",
        "        print(best_iteration, best_RMSE)\n",
        "        return training_process\n",
        "\n",
        "    # w, v 업데이트를 위한 Stochastic gradient descent\n",
        "    def sgd(self, x_data, y_data):\n",
        "        y_pred = []\n",
        "        for data, y in zip(x_data, y_data):\n",
        "            x_idx = data[0]\n",
        "            x_0 = np.array(data[1]) # xi axis=0 [1, 2, 3]\n",
        "            x_1 = x_0.reshape(-1, 1) # xi axis=1 [[1], [2], [3]]\n",
        "\n",
        "            # biases\n",
        "            bias_score = np.sum(self.w[x_idx] * x_0)\n",
        "\n",
        "            # score 계산\n",
        "            vx = self.v[x_idx] * (x_1) # v matrix * x\n",
        "            sum_vx = np.sum(vx, axis=0) # sigma(vx)\n",
        "            sum_vx_2 = np.sum(vx * vx, axis=0) # ( v matrix * x )의 제곱\n",
        "            latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
        "\n",
        "            # 예측값 계산\n",
        "            y_hat = bias_score + latent_score\n",
        "            y_pred.append(y_hat)\n",
        "            error = y - y_hat\n",
        "            # w, v 업데이트\n",
        "            if self.l2_reg: # regularization 있는 경우\n",
        "                self.w[x_idx] += error * self.alpha * (x_0 - self.beta * self.w[x_idx])\n",
        "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1) - self.beta * self.v[x_idx])\n",
        "            else: # regularization 없는 경우\n",
        "                self.w[x_idx] += error * self.alpha * x_0\n",
        "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1))\n",
        "        return RMSE(y_data, y_pred)\n",
        "\n",
        "    def test_rmse(self, x_data, y_data):\n",
        "        y_pred = []\n",
        "        for data , y in zip(x_data, y_data):\n",
        "            y_hat = self.predict(data[0], data[1])\n",
        "            y_pred.append(y_hat)\n",
        "        return RMSE(y_data, y_pred)\n",
        "\n",
        "    def predict(self, idx, x):\n",
        "        x_0 = np.array(x)\n",
        "        x_1 = x_0.reshape(-1, 1)\n",
        "\n",
        "        # biases\n",
        "        bias_score = np.sum(self.w[idx] * x_0)\n",
        "\n",
        "        # score 계산\n",
        "        vx = self.v[idx] * (x_1)\n",
        "        sum_vx = np.sum(vx, axis=0)\n",
        "        sum_vx_2 = np.sum(vx * vx, axis=0)\n",
        "        latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
        "\n",
        "        # 예측값 계산\n",
        "        y_hat = bias_score + latent_score\n",
        "        return y_hat\n",
        "\n",
        "K = 350\n",
        "fm1 = FM(num_x, K, data, y, alpha=0.0014, beta=0.075, train_ratio=0.75, iterations=600, tolerance=0.0005, l2_reg=True, verbose=True)\n",
        "result = fm1.test()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}